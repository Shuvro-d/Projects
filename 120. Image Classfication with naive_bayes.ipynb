{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-WASZeWsCOaX",
    "outputId": "c07ff435-3a0e-438d-a0e3-e94076e30bf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting segmentation-models\n",
      "  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\n",
      "Collecting image-classifiers==1.0.0\n",
      "  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting efficientnet==1.0.0\n",
      "  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
      "Collecting keras-applications<=1.0.8,>=1.0.7\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 KB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (from efficientnet==1.0.0->segmentation-models) (0.18.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.8/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.21.6)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (3.1.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2023.2.3)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.9.0)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.2.2)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (7.1.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.4.1)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.7.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.15.0)\n",
      "Installing collected packages: keras-applications, image-classifiers, efficientnet, segmentation-models\n",
      "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation-models-1.0.1\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.11.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.30.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.1.21)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.6)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (15.0.6.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.4.0)\n",
      "Collecting gdown\n",
      "  Downloading gdown-4.6.3-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.25.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.9.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Installing collected packages: gdown\n",
      "  Attempting uninstall: gdown\n",
      "    Found existing installation: gdown 4.4.0\n",
      "    Uninstalling gdown-4.4.0:\n",
      "      Successfully uninstalled gdown-4.4.0\n",
      "Successfully installed gdown-4.6.3\n",
      "/usr/local/lib/python3.8/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-Vm4Y4YTPSH_zM3xSTzB9RQvJqiVFwaw\n",
      "To: /content/Tumor.zip\n",
      "100% 156M/156M [00:00<00:00, 168MB/s]\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting patool\n",
      "  Downloading patool-1.12-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: patool\n",
      "Successfully installed patool-1.12\n",
      "patool: Extracting Tumor.zip ...\n",
      "patool: running /usr/bin/7z x -o./Unpack_i3bor71w -- Tumor.zip\n",
      "patool: ... Tumor.zip extracted to `Tumor'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Tumor'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install segmentation-models\n",
    "!pip install tensorflow\n",
    "!pip install --upgrade --no-cache-dir gdown\n",
    "!gdown --id 1-Vm4Y4YTPSH_zM3xSTzB9RQvJqiVFwaw\n",
    "!pip install patool\n",
    "import patoolib\n",
    "patoolib.extract_archive('Tumor.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7B_8GDTgCPSo",
    "outputId": "dcdd1704-d89f-4b74-e996-0390968f6010"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pituitary\n",
      "meningioma\n",
      "glioma\n",
      "notumor\n",
      "pituitary\n",
      "meningioma\n",
      "glioma\n",
      "notumor\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 3s 0us/step\n",
      "179/179 [==============================] - 13s 30ms/step\n",
      "41/41 [==============================] - 2s 41ms/step\n",
      "Test accuracy: 0.7864225781845919\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Model\n",
    "\n",
    "# Set image size\n",
    "SIZE = 128\n",
    "\n",
    "# Load and preprocess training data\n",
    "train_images = []\n",
    "train_labels = [] \n",
    "\n",
    "for directory_path in glob.glob(\"/content/Tumor/Training/*\"):\n",
    "    label = directory_path.split(\"/\")[-1]\n",
    "    print(label)\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        train_images.append(img)\n",
    "        train_labels.append(label)\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "# Load and preprocess testing data\n",
    "test_images = []\n",
    "test_labels = [] \n",
    "for directory_path in glob.glob(\"/content/Tumor/Testing/*\"):\n",
    "    label = directory_path.split(\"/\")[-1]\n",
    "    print(label)\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        test_images.append(img)\n",
    "        test_labels.append(label)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# Extract features from images using a pre-trained ResNet50 model\n",
    "resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))\n",
    "model = Model(inputs=resnet.input, outputs=resnet.output)\n",
    "\n",
    "train_features = model.predict(train_images)\n",
    "test_features = model.predict(test_images)\n",
    "\n",
    "# Reshape features to have one feature vector per image\n",
    "train_features = np.reshape(train_features, (train_features.shape[0], -1))\n",
    "test_features = np.reshape(test_features, (test_features.shape[0], -1))\n",
    "\n",
    "# Encode labels using LabelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(test_labels)\n",
    "test_labels_encoded = le.transform(test_labels)\n",
    "le.fit(train_labels)\n",
    "train_labels_encoded = le.transform(train_labels)\n",
    "\n",
    "# Train Gaussian Naive Bayes model on extracted features\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_features, train_labels_encoded)\n",
    "\n",
    "# Make predictions on test set using extracted features\n",
    "y_pred = gnb.predict(test_features)\n",
    "\n",
    "# Compute accuracy score\n",
    "accuracy = accuracy_score(test_labels_encoded, y_pred)\n",
    "print('Test accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sx5kKa2VVNQJ",
    "outputId": "773d04e7-1bad-40aa-cf80-006fa3a2872d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pituitary\n",
      "meningioma\n",
      "glioma\n",
      "notumor\n",
      "pituitary\n",
      "meningioma\n",
      "glioma\n",
      "notumor\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 0s 0us/step\n",
      "179/179 [==============================] - 15s 39ms/step\n",
      "41/41 [==============================] - 3s 67ms/step\n",
      "Test accuracy: 0.7574370709382151\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "\n",
    "# Set image size\n",
    "SIZE = 128\n",
    "\n",
    "# Load and preprocess training data\n",
    "train_images = []\n",
    "train_labels = [] \n",
    "\n",
    "for directory_path in glob.glob(\"/content/Tumor/Training/*\"):\n",
    "    label = directory_path.split(\"/\")[-1]\n",
    "    print(label)\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        train_images.append(img)\n",
    "        train_labels.append(label)\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "# Load and preprocess testing data\n",
    "test_images = []\n",
    "test_labels = [] \n",
    "for directory_path in glob.glob(\"/content/Tumor/Testing/*\"):\n",
    "    label = directory_path.split(\"/\")[-1]\n",
    "    print(label)\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        test_images.append(img)\n",
    "        test_labels.append(label)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# Extract features from images using a pre-trained ResNet50 model\n",
    "resnet = VGG16(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))\n",
    "model = Model(inputs=resnet.input, outputs=resnet.output)\n",
    "\n",
    "train_features = model.predict(train_images)\n",
    "test_features = model.predict(test_images)\n",
    "\n",
    "# Reshape features to have one feature vector per image\n",
    "train_features = np.reshape(train_features, (train_features.shape[0], -1))\n",
    "test_features = np.reshape(test_features, (test_features.shape[0], -1))\n",
    "\n",
    "# Encode labels using LabelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(test_labels)\n",
    "test_labels_encoded = le.transform(test_labels)\n",
    "le.fit(train_labels)\n",
    "train_labels_encoded = le.transform(train_labels)\n",
    "\n",
    "# Train Gaussian Naive Bayes model on extracted features\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_features, train_labels_encoded)\n",
    "\n",
    "# Make predictions on test set using extracted features\n",
    "y_pred = gnb.predict(test_features)\n",
    "\n",
    "# Compute accuracy score\n",
    "accuracy = accuracy_score(test_labels_encoded, y_pred)\n",
    "print('Test accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9faVRAcV5WG",
    "outputId": "9715a883-4012-43c6-9e47-1bab2ad7725b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pituitary\n",
      "meningioma\n",
      "glioma\n",
      "notumor\n",
      "pituitary\n",
      "meningioma\n",
      "glioma\n",
      "notumor\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80134624/80134624 [==============================] - 4s 0us/step\n",
      "179/179 [==============================] - 17s 49ms/step\n",
      "41/41 [==============================] - 3s 81ms/step\n",
      "Test accuracy: 0.7803203661327232\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from keras.models import Model\n",
    "\n",
    "# Set image size\n",
    "SIZE = 128\n",
    "\n",
    "# Load and preprocess training data\n",
    "train_images = []\n",
    "train_labels = [] \n",
    "\n",
    "for directory_path in glob.glob(\"/content/Tumor/Training/*\"):\n",
    "    label = directory_path.split(\"/\")[-1]\n",
    "    print(label)\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        train_images.append(img)\n",
    "        train_labels.append(label)\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "# Load and preprocess testing data\n",
    "test_images = []\n",
    "test_labels = [] \n",
    "for directory_path in glob.glob(\"/content/Tumor/Testing/*\"):\n",
    "    label = directory_path.split(\"/\")[-1]\n",
    "    print(label)\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        test_images.append(img)\n",
    "        test_labels.append(label)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# Extract features from images using a pre-trained ResNet50 model\n",
    "resnet = VGG19(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))\n",
    "model = Model(inputs=resnet.input, outputs=resnet.output)\n",
    "\n",
    "train_features = model.predict(train_images)\n",
    "test_features = model.predict(test_images)\n",
    "\n",
    "# Reshape features to have one feature vector per image\n",
    "train_features = np.reshape(train_features, (train_features.shape[0], -1))\n",
    "test_features = np.reshape(test_features, (test_features.shape[0], -1))\n",
    "\n",
    "# Encode labels using LabelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(test_labels)\n",
    "test_labels_encoded = le.transform(test_labels)\n",
    "le.fit(train_labels)\n",
    "train_labels_encoded = le.transform(train_labels)\n",
    "\n",
    "# Train Gaussian Naive Bayes model on extracted features\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_features, train_labels_encoded)\n",
    "\n",
    "# Make predictions on test set using extracted features\n",
    "y_pred = gnb.predict(test_features)\n",
    "\n",
    "# Compute accuracy score\n",
    "accuracy = accuracy_score(test_labels_encoded, y_pred)\n",
    "print('Test accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ACmzDZvsXSmH",
    "outputId": "3c9e015e-b41c-4108-a2e4-b97dafa174bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pituitary\n",
      "meningioma\n",
      "glioma\n",
      "notumor\n",
      "pituitary\n",
      "meningioma\n",
      "glioma\n",
      "notumor\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 5s 0us/step\n",
      "179/179 [==============================] - 13s 26ms/step\n",
      "41/41 [==============================] - 2s 41ms/step\n",
      "Test accuracy: 0.6323417238749046\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model\n",
    "\n",
    "# Set image size\n",
    "SIZE = 128\n",
    "\n",
    "# Load and preprocess training data\n",
    "train_images = []\n",
    "train_labels = [] \n",
    "\n",
    "for directory_path in glob.glob(\"/content/Tumor/Training/*\"):\n",
    "    label = directory_path.split(\"/\")[-1]\n",
    "    print(label)\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        train_images.append(img)\n",
    "        train_labels.append(label)\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "# Load and preprocess testing data\n",
    "test_images = []\n",
    "test_labels = [] \n",
    "for directory_path in glob.glob(\"/content/Tumor/Testing/*\"):\n",
    "    label = directory_path.split(\"/\")[-1]\n",
    "    print(label)\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        test_images.append(img)\n",
    "        test_labels.append(label)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# Extract features from images using a pre-trained ResNet50 model\n",
    "resnet = InceptionV3(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))\n",
    "model = Model(inputs=resnet.input, outputs=resnet.output)\n",
    "\n",
    "train_features = model.predict(train_images)\n",
    "test_features = model.predict(test_images)\n",
    "\n",
    "# Reshape features to have one feature vector per image\n",
    "train_features = np.reshape(train_features, (train_features.shape[0], -1))\n",
    "test_features = np.reshape(test_features, (test_features.shape[0], -1))\n",
    "\n",
    "# Encode labels using LabelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(test_labels)\n",
    "test_labels_encoded = le.transform(test_labels)\n",
    "le.fit(train_labels)\n",
    "train_labels_encoded = le.transform(train_labels)\n",
    "\n",
    "# Train Gaussian Naive Bayes model on extracted features\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_features, train_labels_encoded)\n",
    "\n",
    "# Make predictions on test set using extracted features\n",
    "y_pred = gnb.predict(test_features)\n",
    "\n",
    "# Compute accuracy score\n",
    "accuracy = accuracy_score(test_labels_encoded, y_pred)\n",
    "print('Test accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8qLIyEUXx6q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
