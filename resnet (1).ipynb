{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2IIwP7NCAeI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5df8cc8-1127-4ffd-c30d-439a3eb0351f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.9.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.28.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (5.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input, ZeroPadding2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import ResNet50"
      ],
      "metadata": {
        "id": "RlYntzmzCE5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(input, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "xyguFxB7Chzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def decoder_block(input, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x"
      ],
      "metadata": {
        "id": "qaxXgoI_UmsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_resnet50_unet(input_shape):\n",
        "    \"\"\" Input \"\"\"\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    \"\"\" Pre-trained ResNet50 Model \"\"\"\n",
        "    resnet50 = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
        "\n",
        "    \"\"\" Encoder \"\"\"\n",
        "    s1 = resnet50.get_layer(\"input_1\").output           ## (512 x 512)\n",
        "    s2 = resnet50.get_layer(\"conv1_relu\").output        ## (256 x 256)\n",
        "    s3 = resnet50.get_layer(\"conv2_block3_out\").output  ## (128 x 128)\n",
        "    s4 = resnet50.get_layer(\"conv3_block4_out\").output  ## (64 x 64)\n",
        "\n",
        "    \"\"\" Bridge \"\"\"\n",
        "    b1 = resnet50.get_layer(\"conv4_block6_out\").output  ## (32 x 32)\n",
        "\n",
        "    \"\"\" Decoder \"\"\"\n",
        "    d1 = decoder_block(b1, s4, 512)                     ## (64 x 64)\n",
        "    d2 = decoder_block(d1, s3, 256)                     ## (128 x 128)\n",
        "    d3 = decoder_block(d2, s2, 128)                     ## (256 x 256)\n",
        "    d4 = decoder_block(d3, s1, 64)                      ## (512 x 512)\n",
        "\n",
        "    \"\"\" Output \"\"\"\n",
        "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"ResNet50_U-Net\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "SFc6n4LlDEDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import keras\n",
        "from keras.utils import normalize\n",
        "from keras.metrics import MeanIoU\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Recall, Precision\n",
        " \n",
        "\n",
        "\"\"\" Global parameters \"\"\"\n",
        "H = 256\n",
        "W = 256\n",
        "def create_dir(path):\n",
        "    \"\"\" Create a directory. \"\"\"\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def load_data(path, split=0.1):\n",
        "    images = sorted(glob(os.path.join(path,\"Images\", \"*.png\")))\n",
        "    masks1 = sorted(glob(os.path.join(path,\"Left\", \"*.png\")))\n",
        "    masks2 = sorted(glob(os.path.join(path,\"Right\", \"*.png\")))\n",
        "\n",
        "    split_size = int(len(images) * split)\n",
        "\n",
        "    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n",
        "    train_y1, valid_y1 = train_test_split(masks1, test_size=split_size, random_state=42)\n",
        "    train_y2, valid_y2 = train_test_split(masks2, test_size=split_size, random_state=42)\n",
        "\n",
        "    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
        "    train_y1, test_y1 = train_test_split(train_y1, test_size=split_size, random_state=42)\n",
        "    train_y2, test_y2 = train_test_split(train_y2, test_size=split_size, random_state=42)\n",
        "\n",
        "    return (train_x, train_y1, train_y2), (valid_x, valid_y1, valid_y2), (test_x, test_y1, test_y2)\n",
        "\n",
        "\n",
        "def read_image(path):\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    x = cv2.resize(x, (W, H))\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.float32)\n",
        "    return x\n",
        "\n",
        "def read_mask(path1, path2):\n",
        "    x1 = cv2.imread(path1, cv2.IMREAD_GRAYSCALE)\n",
        "    x2 = cv2.imread(path2, cv2.IMREAD_GRAYSCALE)\n",
        "    x = x1 + x2\n",
        "    x = cv2.resize(x, (W, H))\n",
        "    x = x/np.max(x)\n",
        "    x = x > 0.5\n",
        "    x = x.astype(np.float32)\n",
        "    x = np.expand_dims(x, axis=-1)\n",
        "    return x\n",
        "\n",
        "def tf_parse(x, y1, y2):\n",
        "    def _parse(x, y1, y2):\n",
        "        x = x.decode()\n",
        "        y1 = y1.decode()\n",
        "        y2 = y2.decode()\n",
        "\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y1, y2)\n",
        "        return x, y\n",
        "\n",
        "    x, y = tf.numpy_function(_parse, [x, y1, y2], [tf.float32, tf.float32])\n",
        "    x.set_shape([H, W, 3])\n",
        "    y.set_shape([H, W, 1])\n",
        "    return x, y\n",
        "def tf_dataset(X, Y1, Y2, batch=8):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X, Y1, Y2))\n",
        "    dataset = dataset.shuffle(buffer_size=200)\n",
        "    dataset = dataset.map(tf_parse)\n",
        "    dataset = dataset.batch(batch)\n",
        "    dataset = dataset.prefetch(4)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "l9bkUK3VDV58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def iou(y_true, y_pred):\n",
        "    def f(y_true, y_pred):\n",
        "        intersection = (y_true * y_pred).sum()\n",
        "        union = y_true.sum() + y_pred.sum() - intersection\n",
        "        x = (intersection + 1e-15) / (union + 1e-15)\n",
        "        x = x.astype(np.float32)\n",
        "        return x\n",
        "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n",
        "\n",
        "smooth = 1e-15\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)\n",
        "     "
      ],
      "metadata": {
        "id": "skbH1FMyVQLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    \"\"\" Seeding \"\"\"\n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    \"\"\" Directory for storing files \"\"\"\n",
        "    create_dir(\"files\")\n",
        "\n",
        "    \"\"\" Hyperparameters \"\"\"\n",
        "    batch_size = 8\n",
        "    lr = 1e-5\n",
        "    num_epochs = 10\n",
        "    model_path = os.path.join(\"files\", \"Final_model_unet_resnet.h5\")\n",
        "    csv_path = os.path.join(\"files\", \"Final_data_unet_resnet.csv\")\n",
        "    \n",
        "    \"\"\" Dataset \"\"\"\n",
        "    dataset_path = \"/content/drive/MyDrive/Data_segment/Train\"\n",
        "    (train_x, train_y1, train_y2), (valid_x, valid_y1, valid_y2),(test_x, test_y1, test_y2)  = load_data(dataset_path)\n",
        "\n",
        "    print(f\"Train: {len(train_x)} - {len(train_y1)} - {len(train_y2)}\")\n",
        "    print(f\"Valid: {len(valid_x)} - {len(valid_y1)} - {len(valid_y2)}\")\n",
        "    print(f\"Test: {len(test_x)} - {len(test_y1)} - {len(test_y2)}\")\n",
        "   \n",
        "\n",
        "    train_dataset = tf_dataset(train_x, train_y1, train_y2, batch=batch_size)\n",
        "    valid_dataset = tf_dataset(valid_x, valid_y1, valid_y2, batch=batch_size) \n",
        "\n",
        "\n",
        "    model = build_resnet50_unet((H,W,3))\n",
        "    #model.summary()\n",
        "    metrics = [dice_coef, iou, Recall(), Precision()]\n",
        "    model.compile(loss=dice_loss, optimizer=Adam(lr), metrics=[\"accuracy\",metrics])\n",
        "\n",
        "    callbacks = [\n",
        "        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
        "        CSVLogger(csv_path)\n",
        "    ]\n",
        "\n",
        "    model.fit(\n",
        "        train_dataset,\n",
        "        epochs=num_epochs,\n",
        "        validation_data=valid_dataset,\n",
        "        callbacks=callbacks\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FCEQA1rVSwo",
        "outputId": "4a9482ba-27d8-4e71-9381-e3ab396e5733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 320 - 320 - 320\n",
            "Valid: 40 - 40 - 40\n",
            "Test: 40 - 40 - 40\n",
            "Epoch 1/10\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.9240 - accuracy: 0.4170 - dice_coef: 0.0760 - iou: 0.0396 - recall: 0.8473 - precision: 0.0461\n",
            "Epoch 1: val_loss improved from inf to 0.93850, saving model to files/Final_model_unet_resnet.h5\n",
            "40/40 [==============================] - 204s 4s/step - loss: 0.9240 - accuracy: 0.4170 - dice_coef: 0.0760 - iou: 0.0396 - recall: 0.8473 - precision: 0.0461 - val_loss: 0.9385 - val_accuracy: 0.3590 - val_dice_coef: 0.0615 - val_iou: 0.0317 - val_recall: 0.6338 - val_precision: 0.0320 - lr: 1.0000e-05\n",
            "Epoch 2/10\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8857 - accuracy: 0.5563 - dice_coef: 0.1143 - iou: 0.0607 - recall: 0.9958 - precision: 0.0689\n",
            "Epoch 2: val_loss did not improve from 0.93850\n",
            "40/40 [==============================] - 20s 503ms/step - loss: 0.8857 - accuracy: 0.5563 - dice_coef: 0.1143 - iou: 0.0607 - recall: 0.9958 - precision: 0.0689 - val_loss: 0.9390 - val_accuracy: 0.3208 - val_dice_coef: 0.0610 - val_iou: 0.0314 - val_recall: 0.6625 - val_precision: 0.0315 - lr: 1.0000e-05\n",
            "Epoch 3/10\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8476 - accuracy: 0.7766 - dice_coef: 0.1524 - iou: 0.0825 - recall: 0.9998 - precision: 0.1286\n",
            "Epoch 3: val_loss did not improve from 0.93850\n",
            "40/40 [==============================] - 20s 503ms/step - loss: 0.8476 - accuracy: 0.7766 - dice_coef: 0.1524 - iou: 0.0825 - recall: 0.9998 - precision: 0.1286 - val_loss: 0.9397 - val_accuracy: 0.0399 - val_dice_coef: 0.0603 - val_iou: 0.0311 - val_recall: 1.0000 - val_precision: 0.0330 - lr: 1.0000e-05\n",
            "Epoch 4/10\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8023 - accuracy: 0.9226 - dice_coef: 0.1977 - iou: 0.1098 - recall: 0.9999 - precision: 0.2989\n",
            "Epoch 4: val_loss improved from 0.93850 to 0.93823, saving model to files/Final_model_unet_resnet.h5\n",
            "40/40 [==============================] - 21s 529ms/step - loss: 0.8023 - accuracy: 0.9226 - dice_coef: 0.1977 - iou: 0.1098 - recall: 0.9999 - precision: 0.2989 - val_loss: 0.9382 - val_accuracy: 0.0347 - val_dice_coef: 0.0618 - val_iou: 0.0319 - val_recall: 1.0000 - val_precision: 0.0329 - lr: 1.0000e-05\n",
            "Epoch 5/10\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7548 - accuracy: 0.9603 - dice_coef: 0.2452 - iou: 0.1399 - recall: 0.9991 - precision: 0.4538\n",
            "Epoch 5: val_loss did not improve from 0.93823\n",
            "40/40 [==============================] - 21s 522ms/step - loss: 0.7548 - accuracy: 0.9603 - dice_coef: 0.2452 - iou: 0.1399 - recall: 0.9991 - precision: 0.4538 - val_loss: 0.9391 - val_accuracy: 0.0471 - val_dice_coef: 0.0609 - val_iou: 0.0314 - val_recall: 0.9998 - val_precision: 0.0333 - lr: 1.0000e-05\n",
            "Epoch 6/10\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7097 - accuracy: 0.9795 - dice_coef: 0.2903 - iou: 0.1700 - recall: 0.9977 - precision: 0.6170\n",
            "Epoch 6: val_loss did not improve from 0.93823\n",
            "40/40 [==============================] - 20s 500ms/step - loss: 0.7097 - accuracy: 0.9795 - dice_coef: 0.2903 - iou: 0.1700 - recall: 0.9977 - precision: 0.6170 - val_loss: 0.9403 - val_accuracy: 0.3147 - val_dice_coef: 0.0597 - val_iou: 0.0308 - val_recall: 0.7042 - val_precision: 0.0331 - lr: 1.0000e-05\n",
            "Epoch 7/10\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6755 - accuracy: 0.9876 - dice_coef: 0.3245 - iou: 0.1938 - recall: 0.9970 - precision: 0.7285\n",
            "Epoch 7: val_loss did not improve from 0.93823\n",
            "40/40 [==============================] - 21s 506ms/step - loss: 0.6755 - accuracy: 0.9876 - dice_coef: 0.3245 - iou: 0.1938 - recall: 0.9970 - precision: 0.7285 - val_loss: 0.9434 - val_accuracy: 0.7760 - val_dice_coef: 0.0566 - val_iou: 0.0291 - val_recall: 0.0585 - val_precision: 0.0098 - lr: 1.0000e-05\n",
            "Epoch 8/10\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6534 - accuracy: 0.9909 - dice_coef: 0.3466 - iou: 0.2098 - recall: 0.9965 - precision: 0.7854\n",
            "Epoch 8: val_loss did not improve from 0.93823\n",
            "40/40 [==============================] - 21s 508ms/step - loss: 0.6534 - accuracy: 0.9909 - dice_coef: 0.3466 - iou: 0.2098 - recall: 0.9965 - precision: 0.7854 - val_loss: 0.9435 - val_accuracy: 0.8878 - val_dice_coef: 0.0565 - val_iou: 0.0291 - val_recall: 0.0472 - val_precision: 0.0188 - lr: 1.0000e-05\n",
            "Epoch 9/10\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6391 - accuracy: 0.9924 - dice_coef: 0.3609 - iou: 0.2204 - recall: 0.9969 - precision: 0.8141\n",
            "Epoch 9: val_loss improved from 0.93823 to 0.93432, saving model to files/Final_model_unet_resnet.h5\n",
            "40/40 [==============================] - 22s 531ms/step - loss: 0.6391 - accuracy: 0.9924 - dice_coef: 0.3609 - iou: 0.2204 - recall: 0.9969 - precision: 0.8141 - val_loss: 0.9343 - val_accuracy: 0.8926 - val_dice_coef: 0.0657 - val_iou: 0.0340 - val_recall: 0.1563 - val_precision: 0.0605 - lr: 1.0000e-05\n",
            "Epoch 10/10\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6281 - accuracy: 0.9935 - dice_coef: 0.3719 - iou: 0.2286 - recall: 0.9971 - precision: 0.8368\n",
            "Epoch 10: val_loss improved from 0.93432 to 0.92459, saving model to files/Final_model_unet_resnet.h5\n",
            "40/40 [==============================] - 22s 532ms/step - loss: 0.6281 - accuracy: 0.9935 - dice_coef: 0.3719 - iou: 0.2286 - recall: 0.9971 - precision: 0.8368 - val_loss: 0.9246 - val_accuracy: 0.8986 - val_dice_coef: 0.0754 - val_iou: 0.0392 - val_recall: 0.2114 - val_precision: 0.0841 - lr: 1.0000e-05\n"
          ]
        }
      ]
    }
  ]
}